{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGLLepz2jvSP",
        "outputId": "f70e042b-8e6d-43ac-ed54-6659d384935b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: Levenshtein==0.27.1 in /usr/local/lib/python3.11/dist-packages (from python-Levenshtein) (0.27.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy python-Levenshtein\n",
        "# Basic text processing\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "# NLP libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from collections import Counter\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "# SpaCy for advanced NLP\n",
        "import spacy\n",
        "\n",
        "# Text preprocessing with scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Optional: pandas and numpy for data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--- Tokenization with CamelCase Support ---\n",
        "def tokenize_enhanced(text):\n",
        "    if pd.isnull(text):\n",
        "        return []\n",
        "    spaced = re.sub('([a-z])([A-Z])', r'\\1 \\2', text)\n",
        "    return re.findall(r'\\b\\w+\\b', spaced.lower())\n"
      ],
      "metadata": {
        "id": "lYw5DPj6lCdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Data ---\n",
        "df = pd.read_excel(\"/content/GP LP mapping list.xlsx\", sheet_name='LP')\n",
        "print (df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnMn1eP4m0LF",
        "outputId": "baf5487e-548a-4a14-920f-a9229f63a8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Region                       LP  Match                    Company Name  \\\n",
            "0  Americas                     1864    NaN                    1010 Capital   \n",
            "1      APAC       1010 Family Office    NaN  1199SEIU National Benefit Fund   \n",
            "2    Europe                   Abbott    NaN                          123 IM   \n",
            "3    Europe                      ABN    NaN                 1693 Management   \n",
            "4        ME  Abu Dhabi Capital Group    NaN                   1823 Partners   \n",
            "\n",
            "     Country  \n",
            "0  Australia  \n",
            "1        USA  \n",
            "2     France  \n",
            "3        USA  \n",
            "4        USA  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_token_frequency(company_names):\n",
        "    tokenized = company_names.dropna().apply(tokenize_enhanced)\n",
        "    tokens = [token for sublist in tokenized for token in sublist]\n",
        "    return Counter(tokens)"
      ],
      "metadata": {
        "id": "SJ3sVUERprzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def improved_token_match(lp_value, choices, token_freq):\n",
        "    if pd.isnull(lp_value):\n",
        "        return None, None\n",
        "\n",
        "    lp_tokens = tokenize_enhanced(lp_value)\n",
        "    lp_nums = [t for t in lp_tokens if t.isdigit()]\n",
        "    lp_words = [t for t in lp_tokens if not t.isdigit()]\n",
        "\n",
        "    best_match = None\n",
        "    best_score = 0\n",
        "\n",
        "    for company in choices:\n",
        "        company_tokens = tokenize_enhanced(company)\n",
        "        company_nums = [t for t in company_tokens if t.isdigit()]\n",
        "        numeric_overlap = len(set(lp_nums) & set(company_nums))\n",
        "\n",
        "        if numeric_overlap > 0:\n",
        "            score = 1000 * numeric_overlap\n",
        "        else:\n",
        "            score = sum(token_freq[token] for token in lp_words if token in company_tokens)\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_match = company\n",
        "\n",
        "    return best_match, min(100, best_score) if best_score > 0 else None\n",
        "\n",
        "# --- Highlight Inaccurate Matches ---\n",
        "def is_inaccurate(lp, match):\n",
        "    if pd.isnull(lp) or pd.isnull(match):\n",
        "        return True\n",
        "    lp_tokens = set(tokenize_enhanced(lp))\n",
        "    match_tokens = set(tokenize_enhanced(match))\n",
        "    return len(lp_tokens & match_tokens) == 0\n"
      ],
      "metadata": {
        "id": "fFtiozR0pvBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_matching(df):\n",
        "    company_names = df['Company Name'].dropna().unique().tolist()\n",
        "    token_freq = build_token_frequency(df['Company Name'])\n",
        "    results = df['LP'].apply(lambda x: improved_token_match(x, company_names, token_freq))\n",
        "    df['Match'] = results.apply(lambda x: x[0])\n",
        "    df['Score %'] = results.apply(lambda x: x[1])\n",
        "    df['Flag'] = df.apply(lambda row: 'Check' if is_inaccurate(row['LP'], row['Match']) else '', axis=1)\n",
        "    return df[['LP', 'Match', 'Score %', 'Flag', 'Company Name']]"
      ],
      "metadata": {
        "id": "lTCHVb8hp0By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the matching\n",
        "processed_df = process_matching(df)\n",
        "\n",
        "\n",
        "# Display in notebook\n",
        "print(processed_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhRoRuemrVJm",
        "outputId": "989b3837-9404-4f2c-cb94-3dd18da0398a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           LP                    Match  Score %   Flag  \\\n",
            "0                        1864            1864 Holdings    100.0          \n",
            "1          1010 Family Office             1010 Capital    100.0          \n",
            "2                      Abbott           Abbott Capital      2.0          \n",
            "3                         ABN                 ABN AMRO      2.0          \n",
            "4     Abu Dhabi Capital Group  Abu Dhabi Capital Group    100.0          \n",
            "...                       ...                      ...      ...    ...   \n",
            "3059                      NaN                     None      NaN  Check   \n",
            "3060                      NaN                     None      NaN  Check   \n",
            "3061                      NaN                     None      NaN  Check   \n",
            "3062                      NaN                     None      NaN  Check   \n",
            "3063                      NaN                     None      NaN  Check   \n",
            "\n",
            "                        Company Name  \n",
            "0                       1010 Capital  \n",
            "1     1199SEIU National Benefit Fund  \n",
            "2                             123 IM  \n",
            "3                    1693 Management  \n",
            "4                      1823 Partners  \n",
            "...                              ...  \n",
            "3059                        Zenrosai  \n",
            "3060      Zirconium Property Pte Ltd  \n",
            "3061                             ZKB  \n",
            "3062                    Zoma Capital  \n",
            "3063                   Zurich Invest  \n",
            "\n",
            "[3064 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Excel file\n",
        "output_path = 'matched_output.xlsx'\n",
        "processed_df.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"Matching results saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwIsF5KNr-sh",
        "outputId": "f48d89f3-296e-406a-fa2f-c8d0d7323c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching results saved to matched_output.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_lp_matching(input_path, sheet_name='LP', output_path='matched_output.xlsx'):\n",
        "    df = pd.read_excel(input_path, sheet_name=sheet_name)\n",
        "    processed_df = process_matching(df)\n",
        "    processed_df.to_excel(output_path, index=False)\n",
        "    print(f\"Matching results saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "y1WdDyxnut1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_lp_matching('/content/GP LP mapping list.xlsx', sheet_name='LP', output_path='matched_output.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBE_GHsouxlk",
        "outputId": "17c630b6-d3c4-4a2a-b123-fb7b65db8390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching results saved to: matched_output.xlsx\n"
          ]
        }
      ]
    }
  ]
}